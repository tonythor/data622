
---
title: "Project 4: MNIST using KNN and Neural Networks"
author: "Team: I Love Lucy"
date: "8 Dec 2024"
output:
  html_document:
    toc: true
    number_sections: true
    self_contained: true
python: 
  jupyter: data622
execute:
#  echo: false
  warning: false
  message: false
  freeze: auto
---
<style>
.quarto-title-meta {
    display: flex;
    justify-content: space-between;
    align-items: center;
    flex-wrap: wrap;
}

.quarto-title-meta-heading {
    font-weight: bold;
}

.quarto-title-meta-contents {
    margin-right: 20px;
}

body {
    width: 900px; /* Lock the body width to 900px */
    font-family: Arial, sans-serif;
    margin: 0 auto; /* Center the body */
    background-color: white; /* Set background to white */
}

/* Flexbox container for title and author */
.header-container {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 20px; /* Add space below the header */
}

.header-container h1 {
    margin: 0;
    font-size: 2.5em;
}

.header-container .meta-info {
    text-align: right; /* Align the meta information (author, date) to the right */
    font-size: 1.2em;
    margin: 0;
}

h2, h3, h4, h5, h6 {
    font-family: Arial, sans-serif;
    margin: 0 0 10px 0; /* Reduce the bottom margin for more compact headers */
    padding: 0; /* Remove padding */
    line-height: 1.2; /* Control the line spacing */
}

/* Adjust table and image styles */
table {
    width: 100%; /* Make table full width within the 900px body */
    border-collapse: collapse;
    max-width: 100%;
    margin-left: auto;  /* Center the table */
    margin-right: auto; /* Center the table */
    overflow-x: auto; /* Allow horizontal scrolling if the table is too wide */
    display: block;
}

table, th, td {
    border: 1px solid lightgray;
    padding: 8px;
    text-align: left;
}

th {
    background-color: #f2f2f2;
}

/* Custom figure sizing */
.figure {
    width: 100%; /* Ensure figures take full width within the 900px body */
    margin-left: auto;  /* Center figure */
    margin-right: auto; /* Center figure */
}

img {
    max-width: 100%;  /* Ensure images take full width within the 900px body */
    height: auto;
    display: block;
    margin-left: auto;  /* Center image */
    margin-right: auto; /* Center image */
}
</style>
<!-- build with:  ./build.sh -p 4 -h -->

<p style="text-align: center;">
  Project 4 Github: [<a href="https://github.com/tonythor/data622/project4.qmd" target="_blank">Quarto Presentation</a>] &nbsp; 
          [<a href="https://github.com/tonythor/data622/mnist.py" target="_blank">Python</a>] &nbsp; 
   &nbsp; | &nbsp; 
  Projects: [<a href="https://rpubs.com/tonythor/data622-project4" target="_blank" >4</a>] &nbsp; 
  [<a href="https://rpubs.com/tonythor/data622-project3" target="_blank" >3</a>] &nbsp; 
  [<a href="https://rpubs.com/tonythor/data622-project2" target="_blank" >2</a>] &nbsp; 
  [<a href="https://rpubs.com/tonythor/data622-project1" target="_blank" >1</a>] &nbsp; 
  
</p>

```{python initial}
from IPython.display import display, HTML
from lussi.mnist import *

X_train, X_test, y_train, y_test, X_train_unscaled = load_data() 
```

# Executive Summary

This project evaluates the performance of K-Nearest Neighbors (KNN) and Neural Networks for handwritten digit recognition using the MNIST dataset. The analysis reveals several key findings:

Performance:
- The Neural Network achieved 97.1% accuracy, outperforming KNN's 94.7% accuracy
- The Neural Network showed more consistent performance across all digits, with accuracy ranging from 95.3% to 98.9%
- KNN showed more variability, with accuracy ranging from 89.9% to 99.2%

Computational Characteristics:
- Training: KNN trained in 4.07 seconds vs. Neural Network's 16.05 seconds
- Prediction Speed: 
  - For small batches (1-100 images), KNN was faster
  - For larger batches (1000 images), Neural Network was significantly faster (0.07ms vs 0.31ms per image)

Error Patterns:
- Both models struggled most with visually similar digits (e.g., 3/5, 4/9, 7/9)
- KNN showed higher error rates for complex digits like '8' (89.9% accuracy)
- Neural Network maintained >95% accuracy across all digit classes

This analysis demonstrates that while KNN offers faster training and competitive performance for small-scale predictions, the Neural Network provides superior accuracy and better scaling for larger batch predictions, making it more suitable for production deployment despite longer training times.

# Project Overview

## History and Significance of MNIST

The [MNIST dataset](https://yann.lecun.com/exdb/mnist/) (Modified National Institute of Standards and Technology) emerged from a practical need at the U.S. Postal Service in the late 1980s. It was created to help automate mail sorting by recognizing handwritten zip codes. Created by Yann LeCun, Corinna Cortes, and Christopher Burges, MNIST has become the de facto "Hello World" of machine learning. The dataset consists of 70,000 handwritten digits (60,000 for training, 10,000 for testing). Its standardized format and manageable size have made it an ideal benchmark for comparing machine learning algorithms for over three decades.

### Understanding the Dataset Format 

Though easily converted, the records are not actually stored as images. They are stored as a matrix. Each record of the 60,000 images is stored as a 28 by 28 matrix, with those positions holding the color of the pixel the position represents. It's a square image, so 28 pixels by 28 pixels tall totals 784 total pixles, or 784 total numbers. Each of those numbers represents a shade of grayscale, 0 being all black, and 255 being white.

```{python initial}
#visualize_digit_matrix(X_train_unscaled, index=0)
matrix_html = visualize_digit_matrix_encoded(X_train_unscaled, index=0)
display(HTML(matrix_html))

```

Wrapping around each of those records, it's like any other machine learning dataset, test and train, and each of those two are broken apart into data and label, like so: 

**Training Set:**

- Images: X_train →  60000  images, each of size  28 \times 28 
- Labels: y_train →  60000  labels, e.g., [5, 0, 4, 1, 9, ...]

**Testing Set:**

- Images: X_test →  10000  images, each of size  28 \times 28 
- Labels: y_test →  10000  labels, e.g., [7, 2, 1, 0, 4, ...]


### Looking at Sample records

It's easy to understand the core challenge by looking at records. There is much variation in hand written letters, with all sorts of factors presenting like: 

* Writing styles and penmanship
* Stroke thickness and continuity
* Digit orientation and slant
* Image noise and quality

```{python sample_digits}
samples_html = plot_sample_digits_encoded(X_train_unscaled, y_train)
display(HTML(samples_html))
# plot_sample_digits(X_train_unscaled, y_train)
```


## Project Goals

This project aims to:

* Compare the effectiveness of a simple, intuitive algorithm (KNN) against a more complex, modern approach (Neural Networks)
* Analyze the tradeoffs between computational complexity and accuracy
* Understand how different architectures handle the variations in handwritten digits
* Evaluate both training time and inference speed for real-world applicability


## Model Implementation and Training

### KNN
```{python knnimpl}
# Train KNN model
print("Training KNN Model...")
start_time = time.time()
knn_model, knn_accuracy = train_knn(X_train, X_test, y_train, y_test, rebuild_model=True)
knn_train_time = time.time() - start_time

print(f"\nKNN Results:")
print(f"Training Time: {knn_train_time:.2f} seconds")
print(f"Accuracy: {knn_accuracy:.4f}")

```



### Neural Network


```{python nnimpl}
print("\nTraining Neural Network...")
start_time = time.time()
nn_model, history, nn_accuracy = train_neural_network(X_train, X_test, y_train, y_test, rebuild_model=True)
nn_train_time = time.time() - start_time

print(f"\nNeural Network Results:")
print(f"Training Time: {nn_train_time:.2f} seconds")
print(f"Accuracy: {nn_accuracy:.4f}")
``` 



----- below has not yet started ---- 



Model Implementation

KNN Implementation

Explanation of how KNN works
Model parameters and choices
Training process


Neural Network Implementation

Architecture explanation
Layer choices and activation functions
Training process and epochs



Model Comparison
The code you provided already includes excellent comparison functionality:

Accuracy metrics
Confusion matrices
Per-digit performance analysis
Training time comparison
Inference time comparison

Custom Prediction Testing

Section for testing with your own handwritten digits
Process for loading and preprocessing custom images
Comparison of how both models perform on your custom input

Would you like me to elaborate on any of these sections or help you implement specific parts of the outline? I can also help you create the actual Quarto markdown structure with code chunks if you'd like.